{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is the code for the Linear Model\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import f_regression \n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pydataset import data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the tips dataset.\n",
    "\n",
    "<li>Create a column named tip_percentage. This should be the tip amount divided by the total bill.\n",
    "<li>Create a column named price_per_person. This should be the total bill divided by the party size.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>size</th>\n",
       "      <th>tip_percentage</th>\n",
       "      <th>price_per_person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059447</td>\n",
       "      <td>0.008704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3</td>\n",
       "      <td>0.160542</td>\n",
       "      <td>0.005297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166587</td>\n",
       "      <td>0.010763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2</td>\n",
       "      <td>0.139780</td>\n",
       "      <td>0.012131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>4</td>\n",
       "      <td>0.146808</td>\n",
       "      <td>0.012597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip  size  tip_percentage  price_per_person\n",
       "1       16.99  1.01     2        0.059447          0.008704\n",
       "2       10.34  1.66     3        0.160542          0.005297\n",
       "3       21.01  3.50     3        0.166587          0.010763\n",
       "4       23.68  3.31     2        0.139780          0.012131\n",
       "5       24.59  3.61     4        0.146808          0.012597"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips= data('tips')\n",
    "tips['tip_percentage']= tips.tip/tips.total_bill\n",
    "tips['price_per_person']= tips.total_bill/tips.size\n",
    "#removing non numeric columns for the purpose of this exercise\n",
    "tips=tips.drop(columns=['sex', 'smoker', 'day', 'time'])\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Before using any of the methods discussed in the lesson, which features do you think would be most important for predicting the tip amount? The tip percentage?<br>\n",
    "  <i>  I think the most important feature for predicting tip amount is the time of the meal and the tip percentage would be sex. </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Use all the other numeric features to predict tip amount. Use select k best and recursive feature elimination to select the top 2 features. What are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.linear_model\n",
    "import sklearn.feature_selection\n",
    "import sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, stratify_by=\"\"):\n",
    "    '''\n",
    "    take in a DataFrame and return train, validate, and test DataFrames.\n",
    "    return train, validate, test DataFrames.\n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "    train, validate = train_test_split(train_validate, \n",
    "                                       test_size=.3, \n",
    "                                       random_state=123)\n",
    "    return train, validate, test\n",
    "train, validate, test = split(tips, stratify_by='tip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((136, 4), (59, 4), (49, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"tip\"\n",
    "\n",
    "# split train into X (dataframe, drop target) & y (series, keep target only)\n",
    "X_train = train.drop(columns=[target])\n",
    "y_train = train[target]\n",
    "\n",
    "# split validate into X (dataframe, drop target) & y (series, keep target only)\n",
    "X_validate = validate.drop(columns=[target])\n",
    "y_validate = validate[target]\n",
    "\n",
    "# split test into X (dataframe, drop target) & y (series, keep target only)\n",
    "X_test = test.drop(columns=[target])\n",
    "y_test = test[target]\n",
    "\n",
    "X_train.shape, X_validate.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Use the scaler to transform train, validate, test\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_validate_scaled = scaler.transform(X_validate)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Use all the other numeric features to predict tip percentage. Use select k best and recursive feature elimination to select the top 2 features. What are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KBest's 2 best features are ['total_bill', 'price_per_person']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Number of features\n",
    "k = 2\n",
    "\n",
    "# Let's start with Select K Best\n",
    "# Make the thing\n",
    "kbest = sklearn.feature_selection.SelectKBest(sklearn.feature_selection.f_regression, k=2)\n",
    "\n",
    "# fit the thing\n",
    "kbest.fit(X_train, y_train)\n",
    "\n",
    "# use the thing, \n",
    "# get_support() produces an array of booleans, so we can filter out the column names that matter the most\n",
    "kbest_features = X_train.columns[kbest.get_support()].tolist()\n",
    "\n",
    "print(\"KBest's 2 best features are\", kbest_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE's 2 best features are ['size', 'tip_percentage']\n"
     ]
    }
   ],
   "source": [
    "# Make the thing(s)\n",
    "lm = sklearn.linear_model.LinearRegression()\n",
    "# # of reafures to use\n",
    "rfe = sklearn.feature_selection.RFE(lm, n_features_to_select=2)\n",
    "\n",
    "# Fit the thing\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# use the thing\n",
    "rfe_columns = X_train.columns[rfe.support_].tolist()\n",
    "\n",
    "print(\"RFE's 2 best features are\", rfe_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Why do you think select k best and recursive feature elimination might give different answers for the top features? Does this change as you change the number of features your are selecting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a function named select_kbest that takes in the predictors (X), the target (y), and the number of features to select (k) and returns the names of the top k selected features based on the SelectKBest class. Test your function with the tips dataset. You should see the same results as when you did the process manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kbest_features(X, y, k):\n",
    "    '''This function takes in a X-Train, Y Train and number of features then returns names of the top number of features based in the K Best Object.'''\n",
    "    # make the object\n",
    "    kbest = sklearn.feature_selection.SelectKBest(sklearn.feature_selection.f_regression, k=k)\n",
    "    # fit the object\n",
    "    kbest.fit(X, y)\n",
    "    # use the object (.get_support() is that array of booleans to filter the list of column names)\n",
    "    return X.columns[kbest.get_support()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total_bill', 'price_per_person']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest_features(X_train, y_train, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a function named rfe that takes in the predictors, the target, and the number of features to select. It should return the top k features based on the RFE class. Test your function with the tips dataset. You should see the same results as when you did the process manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_rankings(X_train, rfe):\n",
    "    \"\"\"\n",
    "    Takes in a dataframe and a fit RFE object in order to output the rank of all features\n",
    "    \"\"\"\n",
    "    # rfe here is reference rfe from cell 15\n",
    "    var_ranks = rfe.ranking_\n",
    "    var_names = X_train.columns.tolist()\n",
    "    ranks = pd.DataFrame({'Var': var_names, 'Rank': var_ranks})\n",
    "    ranks = ranks.sort_values(by=\"Rank\", ascending=True)\n",
    "    return ranks\n",
    "def rfe_features(X, y, r):\n",
    "    ''' This function takes in a X-Train, Y Train and number of features then returns names of the top number of features based on the RFE object.'''\n",
    "    # make the object\n",
    "    lm = sklearn.linear_model.LinearRegression()\n",
    "    rfe = sklearn.feature_selection.RFE(lm, n_features_to_select=k)\n",
    "    # Fit the object\n",
    "    rfe.fit(X, y)\n",
    "    # use the object\n",
    "    features_to_use = X.columns[rfe.support_].tolist()\n",
    "    # we need to send show_feature_rankings a trained/fit RFE object\n",
    "    all_rankings = features_rankings(X, rfe)\n",
    "    return features_to_use, all_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['size', 'tip_percentage'],\n",
       "                 Var  Rank\n",
       " 1              size     1\n",
       " 2    tip_percentage     1\n",
       " 0        total_bill     2\n",
       " 3  price_per_person     3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_features(X_train, y_train, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the swiss dataset and use all the other features to predict Fertility. Find the top 3 features using both select k best and recursive feature elimination (use the functions you just built to help you out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "swiss = data('swiss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train, validate, test = split(swiss, stratify_by=\"Fertility\")\n",
    "\n",
    "# Setup X and y\n",
    "X_train = train.drop(columns='Fertility')\n",
    "y_train = train.Fertility\n",
    "\n",
    "X_validate = validate.drop(columns='Fertility')\n",
    "y_validate = validate.Fertility\n",
    "\n",
    "X_test = test.drop(columns='Fertility')\n",
    "y_test = test.Fertility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Use the scaler to transform train, validate, test\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_validate_scaled = scaler.transform(X_validate)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Turn everything into a dataframe\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_validate_scaled = pd.DataFrame(X_validate_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 2 kbest features are ['Examination', 'Catholic']\n"
     ]
    }
   ],
   "source": [
    "print(\"The top\", k,\"kbest features are\", kbest_features(X_train, y_train, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 2 RFE features are (['Examination', 'Infant.Mortality'],                 Var  Rank\n",
      "1       Examination     1\n",
      "4  Infant.Mortality     1\n",
      "0       Agriculture     2\n",
      "2         Education     3\n",
      "3          Catholic     4)\n"
     ]
    }
   ],
   "source": [
    "print(\"The top\", k,\"RFE features are\", rfe_features(X_train, y_train, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
